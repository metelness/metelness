<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Presence Detection System</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        h1, h2 { color: #333; }
        a { color: #007bff; text-decoration: none; }
        a:hover { text-decoration: underline; }
        pre { background-color: #f4f4f4; padding: 10px; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>Presence Detection System</h1>
    <p><a href="index.html">Back to Home</a></p>
    <h2>Project Overview</h2>
    <p>Developed a system to detect if an individual was present during interactions, combining Python ML for prediction, Teradata SQL for data storage, and SAS for validation. The analysis involved gathering multiple indicators, such as electronic signatures, geolocation comparisons, and fraud-related account activity, to assess presence.</p>
    <h2>Tools Used</h2>
    <ul>
        <li>Python ML: Built a random forest model to predict presence</li>
        <li>Teradata SQL: Stored and queried interaction data</li>
        <li>SAS: Validated model outputs</li>
    </ul>
    <h2>Sample Teradata SQL Code</h2>
    <pre>
/*Multi Indicator Analysis.*/
/*this program will utilize a variety of disparate data sources
to detect if an individual was present at the time of the meeting*/

/*get correct hierarchy of stores for analysis*/
CREATE VOLATILE TABLE org AS (
SELECT
	employee_ID
	,record_obs_eff_dt
	,record_obs_exp_dt
FROM
	schema_b.hierarchy_table
WHERE	
	xyz=TRUE
	And org_lvl_cd = 123
)WITH DATA PRIMARY INDEX(employee_ID,record_obs_eff_dt,record_obs_exp_dt)ON COMMIT PRESERVE ROWS;

/*get the associate's customer meeting data*/
CREATE VOLATILE TABLE t_Transaction_TABLE AS (
    SELECT
        Transaction_Date,
        a.transaction_timestamp, /* Added timestamp */
        employee_ID,
        TRIM(
            TRIM(CAST(a.customer_number AS CHAR(18))) || TRIM(CAST(a.employee_ID AS CHAR(11)))
        ) AS key_,
        customer_number,
        transaction_ID,
        CAST(REGEXP_SUBSTR(a.transaction_ID, '[0-9]+') AS DECIMAL(18,0)) AS transaction_num /*different sources have different data types*/
    FROM 
        schema_b.transaction_activty a
    INNER JOIN 
        schema_b.transaction_reference_table b ON a.ID_ = b.ID_
    INNER JOIN 
        org ON org.employee_ID = a.employee_ID 
        AND a.Transaction_Date BETWEEN org.record_obs_eff_dt AND org.record_obs_exp_dt
) WITH DATA PRIMARY INDEX(key_, transaction_ID, transaction_num) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON t_Transaction_TABLE;
COLLECT STATS COLUMN (Transaction_Date) ON t_Transaction_TABLE;
COLLECT STATS COLUMN (transaction_timestamp) ON t_Transaction_TABLE;
COLLECT STATS COLUMN (employee_ID) ON t_Transaction_TABLE;
COLLECT STATS COLUMN (transaction_ID) ON t_Transaction_TABLE;
COLLECT STATS COLUMN (transaction_num) ON t_Transaction_TABLE;

/* Check for electronic signatures */
CREATE VOLATILE TABLE esignature_data AS (
    SELECT
        a.key_,
        a.transaction_ID,
        CASE 
            WHEN b.esignature_id IS NOT NULL THEN 'Y'
            ELSE 'N'
        END AS esignature_flag
    FROM 
        t_Transaction_TABLE a
    LEFT JOIN 
        schema_b.electronic_signatures b
        ON a.key_ = TRIM(
            TRIM(CAST(b.customer_number AS CHAR(18))) || TRIM(CAST(b.employee_ID AS CHAR(11)))
        )
        AND a.transaction_ID = b.transaction_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON esignature_data;
COLLECT STATS COLUMN (transaction_ID) ON esignature_data;


/* Compare customer's mobile login location to store location */
CREATE VOLATILE TABLE location_comparison AS (
    SELECT
        a.key_,
        a.transaction_ID,
        a.employee_ID,
        /* Simplified distance calculation (in miles) using Haversine formula approximation */
        3959 * ACOS(
            COS(RADIANS(c.customer_lat)) * COS(RADIANS(d.store_lat)) * 
            COS(RADIANS(d.store_lon) - RADIANS(c.customer_lon)) + 
            SIN(RADIANS(c.customer_lat)) * SIN(RADIANS(d.store_lat))
        ) AS distance_miles
    FROM 
        t_Transaction_TABLE a
    INNER JOIN 
        schema_b.mobile_logins c
        ON a.key_ = TRIM(
            TRIM(CAST(c.customer_number AS CHAR(18))) || TRIM(CAST(c.employee_ID AS CHAR(11)))
        )
        AND c.login_timestamp BETWEEN a.transaction_timestamp - INTERVAL '1' HOUR 
                                 AND a.transaction_timestamp + INTERVAL '1' HOUR
    INNER JOIN 
        schema_b.store_locations d
        ON a.employee_ID = d.employee_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON location_comparison;
COLLECT STATS COLUMN (transaction_ID) ON location_comparison;


/* Check if customer lives out of state */
CREATE VOLATILE TABLE out_of_state AS (
    SELECT
        a.key_,
        a.transaction_ID,
        CASE 
            WHEN c.customer_state <> d.store_state THEN 'Y'
            ELSE 'N'
        END AS out_of_state_flag
    FROM 
        t_Transaction_TABLE a
    INNER JOIN 
        schema_b.customer_addresses c
        ON a.key_ = TRIM(
            TRIM(CAST(c.customer_number AS CHAR(18))) || TRIM(CAST(c.employee_ID AS CHAR(11)))
        )
    INNER JOIN 
        schema_b.store_locations d
        ON a.employee_ID = d.employee_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON out_of_state;
COLLECT STATS COLUMN (transaction_ID) ON out_of_state;


/* Parse credit/debit card transactions for out-of-state activity */
CREATE VOLATILE TABLE card_activity AS (
    SELECT
        a.key_,
        a.transaction_ID,
        a.transaction_timestamp,
        CASE 
            WHEN REGEXP_SUBSTR(b.transaction_description, 'STATE:([A-Z]{2})', 1, 1, 'i', 1) <> d.store_state 
            AND b.transaction_type IN ('PURCHASE', 'DEBIT') THEN 'Y'
            ELSE 'N'
        END AS out_of_state_purchase_flag,
        CASE 
            WHEN REGEXP_SUBSTR(b.transaction_description, 'STATE:([A-Z]{2})', 1, 1, 'i', 1) <> d.store_state 
            AND b.transaction_type = 'ATM_WITHDRAWAL' THEN 'Y'
            ELSE 'N'
        END AS out_of_state_atm_flag,
        b.transaction_timestamp AS card_transaction_timestamp,
        b.timezone
    FROM 
        t_Transaction_TABLE a
    INNER JOIN 
        schema_b.card_transactions b
        ON a.key_ = TRIM(
            TRIM(CAST(b.customer_number AS CHAR(18))) || TRIM(CAST(b.employee_ID AS CHAR(11)))
        )
        AND b.transaction_timestamp BETWEEN a.transaction_timestamp - INTERVAL '1' DAY 
                                       AND a.transaction_timestamp + INTERVAL '1' DAY
    INNER JOIN 
        schema_b.store_locations d
        ON a.employee_ID = d.employee_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON card_activity;
COLLECT STATS COLUMN (transaction_ID) ON card_activity;



/* Identify suspicious teller transactions */
CREATE VOLATILE TABLE teller_activity AS (
    SELECT
        a.key_,
        a.transaction_ID,
        CASE 
            WHEN b.override_by_employee = a.employee_ID THEN 'Y'
            ELSE 'N'
        END AS override_flag,
        CASE 
            WHEN b.transaction_type = 'CASH_DEPOSIT' THEN 'Y'
            ELSE 'N'
        END AS cash_deposit_flag
    FROM 
        t_Transaction_TABLE a
    INNER JOIN 
        schema_b.teller_transactions b
        ON a.key_ = TRIM(
            TRIM(CAST(b.customer_number AS CHAR(18))) || TRIM(CAST(b.employee_ID AS CHAR(11)))
        )
        AND a.transaction_ID = b.transaction_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON teller_activity;
COLLECT STATS COLUMN (transaction_ID) ON teller_activity;


/* Aggregate transaction types for closed fraud accounts */
CREATE VOLATILE TABLE fraud_account_activity AS (
    SELECT
        TRIM(
            TRIM(CAST(a.customer_number AS CHAR(18))) || TRIM(CAST(a.employee_ID AS CHAR(11)))
        ) AS key_,
        a.account_id,
        /* Aggregate all transaction types */
        (SUM(CASE WHEN a.transaction_type = 'WIRE_TRANSFER' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'FEE' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'CHECK_WRITTEN' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'DEBIT_CARD_PURCHASE' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'AUTO_TRANSFER' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'BILL_PAY' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'INTERNATIONAL_WIRE' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'MOBILE_DEPOSIT' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'ATM_WITHDRAWAL' THEN a.amount ELSE 0 END) +
         SUM(CASE WHEN a.transaction_type = 'ATM_DEPOSIT' THEN a.amount ELSE 0 END)) 
         / (DATEDIFF(DAY, a.account_open_date, a.account_close_date) + 1) AS fraud_avg_amount
    FROM 
        schema_b.closed_fraud_accounts a
    GROUP BY 
        key_, account_id, account_open_date, account_close_date
) WITH DATA PRIMARY INDEX(key_, account_id) ON COMMIT PRESERVE ROWS;

/* Aggregate transaction types for open accounts */
CREATE VOLATILE TABLE open_account_activity AS (
    SELECT
        TRIM(
            TRIM(CAST(b.customer_number AS CHAR(18))) || TRIM(CAST(b.employee_ID AS CHAR(11)))
        ) AS key_,
        b.account_id,
        (SUM(CASE WHEN b.transaction_type = 'WIRE_TRANSFER' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'FEE' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'CHECK_WRITTEN' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'DEBIT_CARD_PURCHASE' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'AUTO_TRANSFER' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'BILL_PAY' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'INTERNATIONAL_WIRE' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'MOBILE_DEPOSIT' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'ATM_WITHDRAWAL' THEN b.amount ELSE 0 END) +
         SUM(CASE WHEN b.transaction_type = 'ATM_DEPOSIT' THEN b.amount ELSE 0 END)) 
         / (DATEDIFF(DAY, b.account_open_date, CURRENT_DATE) + 1) AS open_avg_amount
    FROM 
        schema_b.open_accounts b
    GROUP BY 
        key_, account_id, account_open_date
) WITH DATA PRIMARY INDEX(key_, account_id) ON COMMIT PRESERVE ROWS;

/* Compare fraud and open account activity */
CREATE VOLATILE TABLE fraud_comparison AS (
    SELECT
        a.key_,
        a.fraud_avg_amount,
        b.open_avg_amount,
        CASE 
            WHEN a.fraud_avg_amount > b.open_avg_amount * 1.5 THEN 'Y'
            ELSE 'N'
        END AS high_risk_flag
    FROM 
        fraud_account_activity a
    INNER JOIN 
        open_account_activity b
        ON a.key_ = b.key_
) WITH DATA PRIMARY INDEX(key_) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON fraud_comparison;



/* Combine all indicators */
CREATE VOLATILE TABLE all_indicators AS (
    SELECT
        a.key_,
        a.transaction_ID,
        b.esignature_flag,
        c.distance_miles,
        d.out_of_state_flag,
        e.out_of_state_purchase_flag,
        e.out_of_state_atm_flag,
        f.override_flag,
        f.cash_deposit_flag,
        g.high_risk_flag
    FROM 
        t_Transaction_TABLE a
    LEFT JOIN 
        esignature_data b ON a.key_ = b.key_ AND a.transaction_ID = b.transaction_ID
    LEFT JOIN 
        location_comparison c ON a.key_ = c.key_ AND a.transaction_ID = c.transaction_ID
    LEFT JOIN 
        out_of_state d ON a.key_ = d.key_ AND a.transaction_ID = d.transaction_ID
    LEFT JOIN 
        card_activity e ON a.key_ = e.key_ AND a.transaction_ID = e.transaction_ID
    LEFT JOIN 
        teller_activity f ON a.key_ = f.key_ AND a.transaction_ID = f.transaction_ID
    LEFT JOIN 
        fraud_comparison g ON a.key_ = g.key_
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;

COLLECT STATS COLUMN (key_) ON all_indicators;
COLLECT STATS COLUMN (transaction_ID) ON all_indicators;


  I’m glad you’re happy with the progress! Let’s enhance your portfolio by adding visualizations to the presence-detection.html page, focusing on the Python analysis you conducted. You mentioned illustrating feature importance, classifier impacts, SHAP values, and a correlation matrix, and you’d like to include a few graphs, including a heatmap of the most impactful classifiers (features) for out_of_state_purchase_flag, cash_deposit_flag, and distance_miles. Since I can’t directly generate images, I’ll provide the Python code to create these visualizations and describe how they would look, then show you how to embed them into your GitHub Pages portfolio.

Step 1: Python Code for Visualizations
Let’s write the Python code to generate the visualizations you described. We’ll use libraries like pandas, matplotlib, seaborn, sklearn, and shap to create the graphs. I’ll assume you’ve exported the all_indicators table from Teradata as a CSV file (all_indicators.csv) for Python analysis.

Python Code
python

Collapse

Wrap

Copy
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import shap
import numpy as np

# Load data
data = pd.read_csv("all_indicators.csv")

# Prepare features and target
features = ['distance_miles', 'esignature_flag', 'out_of_state_flag', 
            'out_of_state_purchase_flag', 'out_of_state_atm_flag', 
            'override_flag', 'cash_deposit_flag', 'high_risk_flag']
data['esignature_flag'] = data['esignature_flag'].map({'Y': 1, 'N': 0})
data['out_of_state_flag'] = data['out_of_state_flag'].map({'Y': 1, 'N': 0})
data['out_of_state_purchase_flag'] = data['out_of_state_purchase_flag'].map({'Y': 1, 'N': 0})
data['out_of_state_atm_flag'] = data['out_of_state_atm_flag'].map({'Y': 1, 'N': 0})
data['override_flag'] = data['override_flag'].map({'Y': 1, 'N': 0})
data['cash_deposit_flag'] = data['cash_deposit_flag'].map({'Y': 1, 'N': 0})
data['high_risk_flag'] = data['high_risk_flag'].map({'Y': 1, 'N': 0})
data.fillna(0, inplace=True)  # Handle missing values

# Assume a target variable (e.g., manually labeled)
data['is_present'] = np.random.randint(0, 2, size=len(data))  # Placeholder for demo

# Split data
X = data[features]
y = data['is_present']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 1. Feature Importance Plot
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure(figsize=(10, 6))
plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [features[i] for i in indices], rotation=45, ha='right')
plt.xlabel("Features")
plt.ylabel("Importance")
plt.tight_layout()
plt.savefig("assets/feature_importance.png")
plt.close()

# 2. Heatmap of Most Impactful Classifiers (out_of_state_purchase_flag, cash_deposit_flag, distance_miles)
subset_features = ['out_of_state_purchase_flag', 'cash_deposit_flag', 'distance_miles']
subset_data = X[subset_features]
correlation_matrix = subset_data.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1, center=0)
plt.title("Correlation Heatmap of Key Classifiers")
plt.tight_layout()
plt.savefig("assets/classifier_heatmap.png")
plt.close()

# 3. SHAP Values (Summary Plot)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
plt.figure(figsize=(10, 6))
shap.summary_plot(shap_values[1], X_test, plot_type="bar", show=False)
plt.title("SHAP Feature Importance")
plt.tight_layout()
plt.savefig("assets/shap_values.png")
plt.close()

# 4. Correlation Matrix (All Features)
plt.figure(figsize=(10, 8))
sns.heatmap(X.corr(), annot=True, cmap="coolwarm", vmin=-1, vmax=1, center=0)
plt.title("Correlation Matrix of All Features")
plt.tight_layout()
plt.savefig("assets/correlation_matrix.png")
plt.close()
Description of Visualizations
Feature Importance Plot (feature_importance.png):
A bar chart showing the importance of each feature in the Random Forest model.
Features like distance_miles, out_of_state_purchase_flag, and cash_deposit_flag might have higher bars if they’re more impactful in predicting presence.
X-axis: Feature names (rotated for readability).
Y-axis: Importance score (0 to 1).
Heatmap of Key Classifiers (classifier_heatmap.png):
A heatmap showing the correlation between out_of_state_purchase_flag, cash_deposit_flag, and distance_miles.
Colors range from blue (negative correlation) to red (positive correlation), with values annotated (e.g., 0.3, -0.1).
If out_of_state_purchase_flag and cash_deposit_flag are positively correlated, you’d see a red square where their row and column intersect.
SHAP Values (shap_values.png):
A bar plot showing the average SHAP values for each feature, indicating their impact on the model’s predictions.
Features are ranked by their mean absolute SHAP value, with distance_miles likely at the top if it’s the most impactful.
X-axis: Mean SHAP value.
Y-axis: Feature names.
Correlation Matrix (correlation_matrix.png):
A heatmap of correlations between all features.
Similar to the classifier heatmap but includes all features (e.g., esignature_flag, high_risk_flag).
Useful for identifying multicollinearity (e.g., if out_of_state_purchase_flag and out_of_state_atm_flag are highly correlated).
Step 2: Update Portfolio Page (presence-detection.html)
Let’s update the presence-detection.html page to include these visualizations. You’ll need to run the Python code above to generate the images and upload them to your assets/ folder in your GitHub Pages repository.

Updated presence-detection.html
html

Preview

Collapse

Wrap

Copy
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Presence Detection System</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        h1, h2 { color: #333; }
        a { color: #007bff; text-decoration: none; }
        a:hover { text-decoration: underline; }
        pre { background-color: #f4f4f4; padding: 10px; border-radius: 5px; }
        img { max-width: 100%; height: auto; margin: 10px 0; }
    </style>
</head>
<body>
    <h1>Presence Detection System</h1>
    <p><a href="index.html">Back to Home</a></p>
    <h2>Project Overview</h2>
    <p>Developed a system to detect if an individual was present during interactions, combining Python ML for prediction, Teradata SQL for data storage, and SAS for validation. The analysis involved gathering multiple indicators, such as electronic signatures, geolocation comparisons, and fraud-related account activity, to assess presence.</p>
    <h2>Tools Used</h2>
    <ul>
        <li>Python ML: Built a random forest model to predict presence</li>
        <li>Teradata SQL: Stored and queried interaction data</li>
        <li>SAS: Validated model outputs</li>
    </ul>
    <h2>Sample Teradata SQL Code</h2>
    <pre>
/* Compare customer's mobile login location to store location */
CREATE VOLATILE TABLE location_comparison AS (
    SELECT
        a.key_,
        a.transaction_ID,
        a.employee_ID,
        3959 * ACOS(
            COS(RADIANS(c.customer_lat)) * COS(RADIANS(d.store_lat)) * 
            COS(RADIANS(d.store_lon) - RADIANS(c.customer_lon)) + 
            SIN(RADIANS(c.customer_lat)) * SIN(RADIANS(d.store_lat))
        ) AS distance_miles
    FROM 
        t_Transaction_TABLE a
    INNER JOIN 
        schema_b.mobile_logins c
        ON a.key_ = TRIM(
            TRIM(CAST(c.customer_number AS CHAR(18))) || TRIM(CAST(c.employee_ID AS CHAR(11)))
        )
        AND c.login_timestamp BETWEEN a.transaction_timestamp - INTERVAL '1' HOUR 
                                 AND a.transaction_timestamp + INTERVAL '1' HOUR
    INNER JOIN 
        schema_b.store_locations d
        ON a.employee_ID = d.employee_ID
) WITH DATA PRIMARY INDEX(key_, transaction_ID) ON COMMIT PRESERVE ROWS;
    </pre>
    <h2>Sample Python Code</h2>
    <pre>
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import shap

# Load data
data = pd.read_csv("all_indicators.csv")

# Prepare features
features = ['distance_miles', 'esignature_flag', 'out_of_state_flag']
data['esignature_flag'] = data['esignature_flag'].map({'Y': 1, 'N': 0})
# ... (encoding for other flags)

# Train model
model = RandomForestClassifier(n_estimators=100)
model.fit(data[features], data['is_present'])

# Generate SHAP values
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(data[features])
    </pre>
    <h2>Visualizations</h2>
    <h3>Feature Importance</h3>
    <img src="assets/feature_importance.png" alt="Feature Importance Plot">
    <p>This bar chart shows the importance of each feature in the Random Forest model, with distance_miles often being the most impactful.</p>
    <h3>Correlation Heatmap of Key Classifiers</h3>
    <img src="assets/classifier_heatmap.png" alt="Correlation Heatmap of Key Classifiers">
    <p>A heatmap showing the correlation between out_of_state_purchase_flag, cash_deposit_flag, and distance_miles, highlighting their relationships.</p>
    <h3>SHAP Values</h3>
    <img src="assets/shap_values.png" alt="SHAP Values">
    <p>SHAP values indicate the impact of each feature on the model's predictions, with distance_miles often having the largest effect.</p>
    <h3>Correlation Matrix</h3>
    <img src="assets/correlation_matrix.png" alt="Correlation Matrix">
    <p>A correlation matrix of all features, useful for identifying multicollinearity between indicators.</p>
</body>
</html>
